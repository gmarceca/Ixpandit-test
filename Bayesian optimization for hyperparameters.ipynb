{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610a5df2",
   "metadata": {},
   "source": [
    "## Load data and usual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "465a5dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>issue_year_mod</th>\n",
       "      <th>earliest_cr_year_mod</th>\n",
       "      <th>emp_length_mod</th>\n",
       "      <th>term_36 months</th>\n",
       "      <th>term_60 months</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>verification_status_Source Verified</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>zip_code_1_0</th>\n",
       "      <th>zip_code_1_1</th>\n",
       "      <th>zip_code_1_2</th>\n",
       "      <th>zip_code_1_3</th>\n",
       "      <th>zip_code_1_4</th>\n",
       "      <th>zip_code_1_5</th>\n",
       "      <th>zip_code_1_6</th>\n",
       "      <th>zip_code_1_7</th>\n",
       "      <th>zip_code_1_8</th>\n",
       "      <th>zip_code_1_9</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1241974</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>12.67</td>\n",
       "      <td>20.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189799</th>\n",
       "      <td>84198.0</td>\n",
       "      <td>20.09</td>\n",
       "      <td>51.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130069</th>\n",
       "      <td>78000.0</td>\n",
       "      <td>15.72</td>\n",
       "      <td>60.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434815</th>\n",
       "      <td>33280.0</td>\n",
       "      <td>21.60</td>\n",
       "      <td>46.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790599</th>\n",
       "      <td>58000.0</td>\n",
       "      <td>26.76</td>\n",
       "      <td>24.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         annual_inc    dti  revol_util  open_acc  pub_rec  total_acc  \\\n",
       "1241974     45000.0  12.67        20.1      12.0      1.0       14.0   \n",
       "1189799     84198.0  20.09        51.1      14.0      0.0       43.0   \n",
       "1130069     78000.0  15.72        60.8      21.0      0.0       44.0   \n",
       "434815      33280.0  21.60        46.4       9.0      0.0       17.0   \n",
       "790599      58000.0  26.76        24.8      29.0      0.0       44.0   \n",
       "\n",
       "         mort_acc  pub_rec_bankruptcies  issue_year_mod  earliest_cr_year_mod  \\\n",
       "1241974       0.0                   0.0              10                    77   \n",
       "1189799       1.0                   0.0               6                    56   \n",
       "1130069       0.0                   0.0               7                    66   \n",
       "434815        0.0                   0.0              11                    76   \n",
       "790599        3.0                   0.0               8                    63   \n",
       "\n",
       "         emp_length_mod  term_36 months  term_60 months  \\\n",
       "1241974             3.0               1               0   \n",
       "1189799            10.0               1               0   \n",
       "1130069             3.0               1               0   \n",
       "434815              1.0               1               0   \n",
       "790599              1.0               0               1   \n",
       "\n",
       "         home_ownership_MORTGAGE  home_ownership_RENT  \\\n",
       "1241974                        0                    1   \n",
       "1189799                        0                    1   \n",
       "1130069                        0                    1   \n",
       "434815                         0                    1   \n",
       "790599                         1                    0   \n",
       "\n",
       "         verification_status_Source Verified  verification_status_Verified  \\\n",
       "1241974                                    1                             0   \n",
       "1189799                                    1                             0   \n",
       "1130069                                    0                             0   \n",
       "434815                                     1                             0   \n",
       "790599                                     0                             0   \n",
       "\n",
       "         purpose_credit_card  purpose_debt_consolidation  zip_code_1_0  \\\n",
       "1241974                    1                           0             0   \n",
       "1189799                    0                           1             0   \n",
       "1130069                    1                           0             0   \n",
       "434815                     1                           0             0   \n",
       "790599                     0                           1             0   \n",
       "\n",
       "         zip_code_1_1  zip_code_1_2  zip_code_1_3  zip_code_1_4  zip_code_1_5  \\\n",
       "1241974             0             0             0             0             0   \n",
       "1189799             0             0             0             1             0   \n",
       "1130069             0             0             0             0             0   \n",
       "434815              0             0             0             0             0   \n",
       "790599              0             1             0             0             0   \n",
       "\n",
       "         zip_code_1_6  zip_code_1_7  zip_code_1_8  zip_code_1_9  \\\n",
       "1241974             0             0             0             1   \n",
       "1189799             0             0             0             0   \n",
       "1130069             0             0             0             1   \n",
       "434815              0             1             0             0   \n",
       "790599              0             0             0             0   \n",
       "\n",
       "         initial_list_status_f  initial_list_status_w  \n",
       "1241974                      1                      0  \n",
       "1189799                      1                      0  \n",
       "1130069                      1                      0  \n",
       "434815                       0                      1  \n",
       "790599                       1                      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "#################################\n",
    "\n",
    "# Remove missing zip_code values.    \n",
    "df = df[df['zip_code'].notna()]\n",
    "\n",
    "# Extract issue year information and add to dataset\n",
    "df['issue_year'] = df['issue_d'].apply(lambda x: int(str(x).split('-')[1]))\n",
    "df['earliest_cr_year'] = df['earliest_cr_line'].apply(lambda x: int(str(x).split('-')[1]))\n",
    "\n",
    "\n",
    "#################################\n",
    "\n",
    "# Split dataset in train/test based on loan_status\n",
    "label_columns = ['loan_status']\n",
    "\n",
    "training_columns = ['emp_length', 'term', 'home_ownership', 'verification_status', 'purpose', 'zip_code',\n",
    "                    'initial_list_status', 'annual_inc', 'dti',\n",
    "                    'revol_util', 'open_acc', 'pub_rec', 'total_acc', 'mort_acc', \n",
    "                    'pub_rec_bankruptcies', 'issue_year', 'earliest_cr_year']\n",
    "\n",
    "# Split the training and validation datasets and their labels.\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[training_columns], df[label_columns],random_state = 1912)\n",
    "\n",
    "y_train['loan_status'] = y_train['loan_status'].apply(lambda x: 0 if x == 'Fully Paid' else 1)\n",
    "y_val['loan_status'] = y_val['loan_status'].apply(lambda x: 0 if x == 'Fully Paid' else 1)\n",
    "\n",
    "#################################\n",
    "\n",
    "# Convert emp_length to ordinal values\n",
    "def convert_emp_length (row):\n",
    "    if type(row['emp_length']) == float:\n",
    "        return np.NaN\n",
    "    if row['emp_length'] == '10+ years':\n",
    "        return 10\n",
    "    if row['emp_length'][0] != '<':\n",
    "        return int(row['emp_length'][0])\n",
    "    if row['emp_length'] == '< 1 year':\n",
    "        return 0\n",
    "    \n",
    "# Convert issue_year to ordinal values\n",
    "def convert_issue_year (row):\n",
    "    return row['issue_year'] - 2006\n",
    "\n",
    "# Convert earliest_cr_year to ordinal values\n",
    "def convert_earliest_cr_year (row):\n",
    "    return row['earliest_cr_year'] - 1934\n",
    "\n",
    "#################################\n",
    "\n",
    "def prep_dataset(dataset):\n",
    "    \n",
    "    # Get 1st digit from zip_code\n",
    "    dataset['zip_code_1'] = dataset['zip_code'].apply(lambda x: str(x)[0:1])\n",
    "\n",
    "    # Remove artificial space from feature 'term'\n",
    "    dataset['term'] = dataset['term'].apply(lambda x: x if str(x)[0] != ' ' else x[1:])\n",
    "\n",
    "    # Fill NaNs with the median\n",
    "    cols = ['annual_inc', 'dti', 'revol_util', 'open_acc', 'pub_rec', 'total_acc', 'mort_acc', \n",
    "            'pub_rec_bankruptcies']\n",
    "    for i in cols:\n",
    "        dataset[i].fillna(dataset[i].median(), inplace = True)\n",
    "    \n",
    "    # Perform ORDINAL ENCODING for emp_length and issue_year\n",
    "    dataset['issue_year_mod'] = dataset.apply (lambda row: convert_issue_year(row), axis=1)\n",
    "    dataset['earliest_cr_year_mod'] = dataset.apply (lambda row: convert_earliest_cr_year(row), axis=1)\n",
    "    dataset['emp_length_mod'] = dataset.apply (lambda row: convert_emp_length(row), axis=1)\n",
    "    dataset['emp_length_mod'].fillna(dataset['emp_length_mod'].median(), inplace = True)\n",
    "    \n",
    "    # Perform ONE-HOT ENCODING    \n",
    "    cols = ['term', 'home_ownership', 'verification_status', 'purpose', 'zip_code_1', \n",
    "            'initial_list_status']\n",
    "    \n",
    "    for i in cols:\n",
    "        dummies = pd.get_dummies(dataset[i], prefix = i, drop_first = False)\n",
    "        dataset = pd.concat([dataset, dummies], axis = 1)\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "X_train = prep_dataset(X_train.copy())\n",
    "X_val = prep_dataset(X_val.copy())\n",
    "\n",
    "#################################\n",
    "\n",
    "# Drop unused columns from this dataset.\n",
    "def drop_unused(dataset):\n",
    "    \n",
    "    # This has been replaced with ordinal encoding.\n",
    "    dataset = dataset.drop(['emp_length'], axis = 1)\n",
    "\n",
    "    # These have been replaced with one-hot encoding.\n",
    "    dataset = dataset.drop(['term'], axis = 1)\n",
    "    dataset = dataset.drop(['home_ownership'], axis = 1)\n",
    "    dataset = dataset.drop(['verification_status'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose'], axis = 1)\n",
    "    dataset = dataset.drop(['zip_code'], axis = 1)\n",
    "    dataset = dataset.drop(['zip_code_1'], axis = 1)\n",
    "    dataset = dataset.drop(['earliest_cr_year'], axis = 1)\n",
    "    dataset = dataset.drop(['issue_year'], axis = 1)\n",
    "    dataset = dataset.drop(['initial_list_status'], axis = 1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "X_train = drop_unused(X_train.copy())\n",
    "X_val = drop_unused(X_val.copy())\n",
    "\n",
    "#################################\n",
    "\n",
    "# Drop not important features from this dataset.\n",
    "def drop_not_important(dataset):\n",
    "    \n",
    "    dataset = dataset.drop(['home_ownership_ANY'], axis = 1)\n",
    "    dataset = dataset.drop(['home_ownership_NONE'], axis = 1)\n",
    "    dataset = dataset.drop(['home_ownership_OTHER'], axis = 1)\n",
    "    dataset = dataset.drop(['home_ownership_OWN'], axis = 1)\n",
    "    dataset = dataset.drop(['verification_status_Not Verified'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_car'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_educational'], axis = 1) \n",
    "    dataset = dataset.drop(['purpose_house'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_major_purchase'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_medical'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_moving'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_renewable_energy'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_small_business'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_vacation'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_wedding'], axis = 1)\n",
    "    \n",
    "    dataset = dataset.drop(['purpose_home_improvement'], axis = 1)\n",
    "    dataset = dataset.drop(['purpose_other'], axis = 1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "X_train = drop_not_important(X_train.copy())\n",
    "X_val = drop_not_important(X_val.copy())\n",
    "\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60f7af",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with hyperopt for hyperparameters search (3-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "325e3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample example of parameters space based on defined distributions:  {'class_weight': None, 'criterion': 'gini', 'max_depth': 17, 'max_features': 'auto', 'min_samples_leaf': 26, 'min_samples_split': 33, 'n_estimators': 45}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score, make_scorer, roc_auc_score\n",
    "\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "N_FOLDS = 3\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "# Define the search space distributions\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced', 'balanced_subsample']),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 40, 1)),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 5, 80, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 40, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 40, 1)),\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'log2'])\n",
    "}\n",
    "                              \n",
    "# Sample from the full space\n",
    "example = hyperopt.pyll.stochastic.sample(space)\n",
    "print('sample example of parameters space based on defined distributions: ', example)\n",
    "\n",
    "import csv\n",
    "\n",
    "# File to save first results\n",
    "out_file = 'rfc_trials.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'train_time'])\n",
    "of_connection.close()\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for RandomForest Classifier for Hyperparameter Tuning\"\"\"\n",
    "    \n",
    "    forest = RandomForestClassifier(**params)\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Evalute based on AUC-ROC\n",
    "    cv_results = np.mean(cross_val_score(forest, X_train, np.ravel(y_train), \n",
    "                                         cv=N_FOLDS, scoring=make_scorer(roc_auc_score)))\n",
    "    \n",
    "    end = time()\n",
    "    train_time = (end - start) * 1000\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - cv_results\n",
    "    \n",
    "    \n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, train_time])\n",
    "    of_connection.close()\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "from hyperopt import tpe # Algorithm\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64a604",
   "metadata": {},
   "source": [
    "## Run bayesian optimization based TPE (commented to avoid waiting times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "554d6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin\n",
    "from hyperopt import Trials# Trials object to track progress\n",
    "bayes_trials = Trials()\n",
    "\n",
    "MAX_EVALS = 500\n",
    "\n",
    "# Uncomment this if you want to run bayesian optimization\n",
    "# # Optimize\n",
    "# best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "#             max_evals = MAX_EVALS, trials = bayes_trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
